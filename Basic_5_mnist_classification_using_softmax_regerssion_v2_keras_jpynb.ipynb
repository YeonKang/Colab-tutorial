{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic_5_mnist_classification_using_softmax_regerssion_v2_keras.jpynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMSct6LT21c2qyihLrkgmta"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tapb-OZ9Fcmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#download MNIST data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "#convert images into float32 data type\n",
        "x_train, x_test = x_train.astype('float32'), x_test.astype('float32')\n",
        "#flattening 28*28 image type into 784 dimensions\n",
        "x_train, x_test = x_train.reshape([-1, 784]), x_test.reshape([-1, 784])\n",
        "#normalizes values ​​between [0, 255] to values ​​between [0, 1]\n",
        "x_train, x_test = x_train / 255., x_test / 255.\n",
        "#apply one-hot encoding to label data\n",
        "y_train, y_test = tf.one_hot(y_train, depth=10), tf.one_hot(y_test, depth=10)\n",
        "\n",
        "#mix data using tf.data API and import it in batch form\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_data = train_data.repeat().shuffle(60000).batch(100)\n",
        "train_data_iter = iter(train_data)\n",
        "\n",
        "#define the Softmax Regression model using tf.keras.Model\n",
        "class SoftmaxRegression(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(SoftmaxRegression, self).__init__()\n",
        "    self.softmax_layer = tf.keras.layers.Dense(10,\n",
        "                                               activation=None,\n",
        "                                               kernel_initializer='zeros',\n",
        "                                               bias_initializer='zeros')\n",
        "\n",
        "  def call(self, x):\n",
        "    logits = self.softmax_layer(x)\n",
        "\n",
        "    return tf.nn.softmax(logits)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}