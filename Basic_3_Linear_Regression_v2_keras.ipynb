{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic_3_Linear_Regression_v2_keras.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMnWqoagq44RU+fIZXZ6+wv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfEilm80PCSl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "96b160ed-e198-40ff-83a0-e71e43e2a889"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "#define linear regression model using tf.keras.Model\n",
        "class LinearRegression(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(LinearRegression, self).__init__()\n",
        "    self.linear_layer = tf.keras.layers.Dense(1, activation=None)\n",
        "\n",
        "  def call(self, x):\n",
        "    y_pred = self.linear_layer(x)\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "#define loss function\n",
        "@tf.function\n",
        "def mse_loss(y_pred, y):\n",
        "  return tf.reduce_mean(tf.square(y_pred - y)) #MSE loss function => mean{(y'-y)^2}\n",
        "\n",
        "#define gradient descent optimizer\n",
        "optimizer = tf.optimizers.SGD(0.01)\n",
        "\n",
        "#define folder address to save tensorboard summary information\n",
        "summary_writer = tf.summary.create_file_writer('./tensorboard_log')\n",
        "\n",
        "#define function for optimization\n",
        "@tf.function\n",
        "def train_step(model, x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    y_pred = model(x)\n",
        "    loss = mse_loss(y_pred, y)\n",
        "\n",
        "  #log tensorboard at every step\n",
        "  with summary_writer.as_default():\n",
        "    tf.summary.scalar('loss', loss, step=optimizer.iterations)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "#set input and output values\n",
        "x_train = [1.0, 2.0, 3.0, 4.0]\n",
        "y_train = [2.0, 4.0, 6.0, 8.0]\n",
        "\n",
        "#get data in batch form using tf.data API\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_data = train_data.repeat().batch(1)\n",
        "train_data_iter = iter(train_data)\n",
        "\n",
        "#define LinearRegression model\n",
        "LinearRegression_model = LinearRegression()\n",
        "\n",
        "#perform gradient descent 1000 times\n",
        "for i in range(1000):\n",
        "  batch_xs, batch_ys = next(train_data_iter)\n",
        "  batch_xs = tf.expand_dims(batch_xs, 0) #expansion of dimension to meet 2-dimension (the minimun imput dimension of tf.keras.layers.Dense API)\n",
        "  train_step(LinearRegression_model, batch_xs, batch_ys)\n",
        "\n",
        "#set input data for test\n",
        "x_test = [3.5, 5.0, 5.5, 6.0]\n",
        "test_data = tf.data.Dataset.from_tensor_slices((x_test))\n",
        "test_data = test_data.batch(1)\n",
        "\n",
        "for batch_x_test in test_data:\n",
        "  batch_x_test = tf.expand_dims(batch_x_test, 0)\n",
        "  print(tf.squeeze(LinearRegression_model(batch_x_test), 0).numpy())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "[6.997228]\n",
            "[9.982493]\n",
            "[10.977582]\n",
            "[11.972671]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}