{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab4_Multi_variable_Linear_Regression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPoxQxcBBBcePEDo9QJsbon",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YeonKang/Tensorflow-with-Colab/blob/master/Lab4_Multi_variable_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4HAhyozwXOT",
        "outputId": "185e3c84-4351-4264-dd06-f3084ed7df0c"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XVBse3tyqqf"
      },
      "source": [
        "**Multi variable Linear Regression** (2 variables)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izIUZnnM0mLE"
      },
      "source": [
        "tf.random.set_seed(0)  #for reproducibility"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ETgKl0M0rvQ",
        "outputId": "f1e758d1-0eb9-4a49-a567-dbb482bcb207"
      },
      "source": [
        "x1_data = [1, 0, 3, 0, 5]\r\n",
        "x2_data = [0, 2, 0, 4, 0]\r\n",
        "y_data  = [1, 2, 3, 4, 5]\r\n",
        "\r\n",
        "W1 = tf.Variable(tf.random.uniform((1,), -10.0, 10.0))\r\n",
        "W2 = tf.Variable(tf.random.uniform((1,), -10.0, 10.0))\r\n",
        "b  = tf.Variable(tf.random.uniform((1,), -10.0, 10.0))\r\n",
        "\r\n",
        "learning_rate = tf.Variable(0.001)\r\n",
        "\r\n",
        "for i in range(1000+1):\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "        hypothesis = W1 * x1_data + W2 * x2_data + b\r\n",
        "        cost = tf.reduce_mean(tf.square(hypothesis - y_data))\r\n",
        "    W1_grad, W2_grad, b_grad = tape.gradient(cost, [W1, W2, b])\r\n",
        "    W1.assign_sub(learning_rate * W1_grad)\r\n",
        "    W2.assign_sub(learning_rate * W2_grad)\r\n",
        "    b.assign_sub(learning_rate * b_grad)\r\n",
        "\r\n",
        "    if i % 50 == 0:\r\n",
        "        print(\"{:5} | {:10.6f} | {:10.4f} | {:10.4f} | {:10.6f}\".format(\r\n",
        "          i, cost.numpy(), W1.numpy()[0], W2.numpy()[0], b.numpy()[0]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    0 | 335.280823 |    -4.0663 |     1.1220 |  -6.065215\n",
            "   50 |  76.037262 |    -0.8001 |     1.6209 |  -4.978779\n",
            "  100 |  18.959263 |     0.7151 |     1.8781 |  -4.429109\n",
            "  150 |   6.310240 |     1.4125 |     2.0104 |  -4.134423\n",
            "  200 |   3.445082 |     1.7284 |     2.0768 |  -3.961648\n",
            "  250 |   2.743659 |     1.8667 |     2.1075 |  -3.847750\n",
            "  300 |   2.525401 |     1.9225 |     2.1184 |  -3.762738\n",
            "  350 |   2.417754 |     1.9402 |     2.1181 |  -3.692262\n",
            "  400 |   2.337300 |     1.9403 |     2.1114 |  -3.629400\n",
            "  450 |   2.264998 |     1.9325 |     2.1008 |  -3.570778\n",
            "  500 |   2.196328 |     1.9213 |     2.0881 |  -3.514729\n",
            "  550 |   2.130126 |     1.9085 |     2.0741 |  -3.460409\n",
            "  600 |   2.066037 |     1.8953 |     2.0595 |  -3.407385\n",
            "  650 |   2.003917 |     1.8819 |     2.0444 |  -3.355424\n",
            "  700 |   1.943679 |     1.8686 |     2.0293 |  -3.304398\n",
            "  750 |   1.885258 |     1.8555 |     2.0141 |  -3.254230\n",
            "  800 |   1.828595 |     1.8425 |     1.9990 |  -3.204873\n",
            "  850 |   1.773636 |     1.8297 |     1.9841 |  -3.156293\n",
            "  900 |   1.720329 |     1.8171 |     1.9693 |  -3.108468\n",
            "  950 |   1.668625 |     1.8048 |     1.9547 |  -3.061379\n",
            " 1000 |   1.618474 |     1.7926 |     1.9403 |  -3.015011\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWQfsxr80vmc"
      },
      "source": [
        "**Multi variable Linear Regression** (2 variables with Matrix)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SIXz5QP00mV",
        "outputId": "eaf995c0-98ce-4b42-cbb5-ae547ae0dfb5"
      },
      "source": [
        "x_data = [\r\n",
        "    [1., 0., 3., 0., 5.],\r\n",
        "    [0., 2., 0., 4., 0.]\r\n",
        "]\r\n",
        "y_data  = [1, 2, 3, 4, 5]\r\n",
        "\r\n",
        "W = tf.Variable(tf.random.uniform((1, 2), -1.0, 1.0))\r\n",
        "b = tf.Variable(tf.random.uniform((1,), -1.0, 1.0))\r\n",
        "\r\n",
        "learning_rate = tf.Variable(0.001)\r\n",
        "\r\n",
        "for i in range(1000+1):\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "        hypothesis = tf.matmul(W, x_data) + b # (1, 2) * (2, 5) = (1, 5)\r\n",
        "        cost = tf.reduce_mean(tf.square(hypothesis - y_data))\r\n",
        "\r\n",
        "        W_grad, b_grad = tape.gradient(cost, [W, b])\r\n",
        "        W.assign_sub(learning_rate * W_grad)\r\n",
        "        b.assign_sub(learning_rate * b_grad)\r\n",
        "    \r\n",
        "    if i % 50 == 0:\r\n",
        "        print(\"{:5} | {:10.6f} | {:10.4f} | {:10.4f} | {:10.6f}\".format(\r\n",
        "            i, cost.numpy(), W.numpy()[0][0], W.numpy()[0][1], b.numpy()[0]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    0 |  36.403778 |    -0.6231 |    -0.3508 |  -0.961774\n",
            "   50 |   9.372901 |     0.2914 |     0.1682 |  -0.557764\n",
            "  100 |   2.639858 |     0.7060 |     0.4867 |  -0.347756\n",
            "  150 |   0.825069 |     0.8912 |     0.6846 |  -0.235665\n",
            "  200 |   0.284990 |     0.9721 |     0.8088 |  -0.174012\n",
            "  250 |   0.106844 |     1.0062 |     0.8873 |  -0.138953\n",
            "  300 |   0.042677 |     1.0195 |     0.9372 |  -0.118279\n",
            "  350 |   0.018044 |     1.0241 |     0.9690 |  -0.105598\n",
            "  400 |   0.008188 |     1.0250 |     0.9893 |  -0.097477\n",
            "  450 |   0.004138 |     1.0246 |     1.0022 |  -0.092026\n",
            "  500 |   0.002439 |     1.0239 |     1.0104 |  -0.088173\n",
            "  550 |   0.001710 |     1.0230 |     1.0156 |  -0.085299\n",
            "  600 |   0.001384 |     1.0223 |     1.0188 |  -0.083036\n",
            "  650 |   0.001227 |     1.0217 |     1.0207 |  -0.081161\n",
            "  700 |   0.001142 |     1.0212 |     1.0218 |  -0.079538\n",
            "  750 |   0.001088 |     1.0207 |     1.0224 |  -0.078080\n",
            "  800 |   0.001046 |     1.0203 |     1.0227 |  -0.076735\n",
            "  850 |   0.001011 |     1.0199 |     1.0227 |  -0.075468\n",
            "  900 |   0.000980 |     1.0196 |     1.0226 |  -0.074258\n",
            "  950 |   0.000949 |     1.0192 |     1.0225 |  -0.073089\n",
            " 1000 |   0.000921 |     1.0189 |     1.0222 |  -0.071954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3p0hvat02gd"
      },
      "source": [
        "**Hypothesis without b**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in4WMjWM068W",
        "outputId": "80ed2de9-e30a-4bf7-e73e-3ad1f4acee4d"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "#in the code above, bias(b) is added to the matrix.\r\n",
        "x_data = [\r\n",
        "    [1., 1., 1., 1., 1.], # bias(b)\r\n",
        "    [1., 0., 3., 0., 5.], \r\n",
        "    [0., 2., 0., 4., 0.]\r\n",
        "]\r\n",
        "y_data  = [1, 2, 3, 4, 5]\r\n",
        "\r\n",
        "W = tf.Variable(tf.random.uniform((1, 3), -1.0, 1.0))\r\n",
        "\r\n",
        "learning_rate = 0.001\r\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate)\r\n",
        "\r\n",
        "for i in range(1000+1):\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "        hypothesis = tf.matmul(W, x_data) #hypothetical function without b(bias)\r\n",
        "        cost = tf.reduce_mean(tf.square(hypothesis - y_data))\r\n",
        "\r\n",
        "    grads = tape.gradient(cost, [W])\r\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(grads,[W]))\r\n",
        "    if i % 50 == 0:\r\n",
        "        print(\"{:5} | {:10.6f} | {:10.4f} | {:10.4f} | {:10.4f}\".format(\r\n",
        "            i, cost.numpy(), W.numpy()[0][0], W.numpy()[0][1], W.numpy()[0][2]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    0 |  16.019751 |    -0.1985 |     0.3424 |    -0.6835\n",
            "   50 |   5.635924 |     0.0582 |     0.6809 |    -0.1215\n",
            "  100 |   2.141112 |     0.1997 |     0.8238 |     0.2356\n",
            "  150 |   0.862825 |     0.2786 |     0.8808 |     0.4641\n",
            "  200 |   0.367091 |     0.3227 |     0.9015 |     0.6112\n",
            "  250 |   0.167513 |     0.3468 |     0.9074 |     0.7064\n",
            "  300 |   0.085210 |     0.3593 |     0.9082 |     0.7684\n",
            "  350 |   0.050615 |     0.3649 |     0.9074 |     0.8090\n",
            "  400 |   0.035731 |     0.3663 |     0.9067 |     0.8359\n",
            "  450 |   0.029064 |     0.3651 |     0.9063 |     0.8539\n",
            "  500 |   0.025846 |     0.3624 |     0.9064 |     0.8661\n",
            "  550 |   0.024085 |     0.3587 |     0.9069 |     0.8746\n",
            "  600 |   0.022948 |     0.3544 |     0.9076 |     0.8807\n",
            "  650 |   0.022085 |     0.3497 |     0.9086 |     0.8852\n",
            "  700 |   0.021348 |     0.3449 |     0.9097 |     0.8887\n",
            "  750 |   0.020676 |     0.3400 |     0.9109 |     0.8916\n",
            "  800 |   0.020042 |     0.3350 |     0.9121 |     0.8940\n",
            "  850 |   0.019434 |     0.3301 |     0.9133 |     0.8960\n",
            "  900 |   0.018848 |     0.3252 |     0.9146 |     0.8979\n",
            "  950 |   0.018280 |     0.3203 |     0.9158 |     0.8997\n",
            " 1000 |   0.017730 |     0.3155 |     0.9171 |     0.9013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa144rl21d6Z"
      },
      "source": [
        "**Custom Gradient**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEPHQSoe1hZf",
        "outputId": "378b0301-f345-4d01-cf9c-c0fcdb981899"
      },
      "source": [
        "#multi-variable linear regression (1)\r\n",
        "\r\n",
        "X = tf.constant([[1., 2.], \r\n",
        "                 [3., 4.]])\r\n",
        "y = tf.constant([[1.5], [3.5]])\r\n",
        "\r\n",
        "W = tf.Variable(tf.random.normal((2, 1)))\r\n",
        "b = tf.Variable(tf.random.normal((1,)))\r\n",
        "\r\n",
        "#create an optimizer\r\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\r\n",
        "\r\n",
        "n_epoch = 1000+1\r\n",
        "print(\"epoch | cost\")\r\n",
        "for i in range(n_epoch):\r\n",
        "    #use tf.GradientTape() to record the gradient of the cost function\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "        y_pred = tf.matmul(X, W) + b\r\n",
        "        cost = tf.reduce_mean(tf.square(y_pred - y))\r\n",
        "\r\n",
        "    #calculates the gradients of the loss\r\n",
        "    grads = tape.gradient(cost, [W, b])\r\n",
        "    \r\n",
        "    #updates parameters (W and b)\r\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(grads, [W, b]))\r\n",
        "    if i % 50 == 0:\r\n",
        "        print(\"{:5} | {:10.6f}\".format(i, cost.numpy()))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch | cost\n",
            "    0 |   8.207649\n",
            "   50 |   0.106266\n",
            "  100 |   0.072655\n",
            "  150 |   0.049675\n",
            "  200 |   0.033963\n",
            "  250 |   0.023221\n",
            "  300 |   0.015876\n",
            "  350 |   0.010855\n",
            "  400 |   0.007422\n",
            "  450 |   0.005074\n",
            "  500 |   0.003469\n",
            "  550 |   0.002372\n",
            "  600 |   0.001622\n",
            "  650 |   0.001109\n",
            "  700 |   0.000758\n",
            "  750 |   0.000518\n",
            "  800 |   0.000354\n",
            "  850 |   0.000242\n",
            "  900 |   0.000166\n",
            "  950 |   0.000113\n",
            " 1000 |   0.000077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQQ8tc1m1sZ0"
      },
      "source": [
        "**Predicting exam score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmORy8lm1u3p"
      },
      "source": [
        "tf.random.set_seed(0) #for reproducibility"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCpKcocl10h6",
        "outputId": "33718345-ce44-417c-ff99-64c83b0ac494"
      },
      "source": [
        "#data and label\r\n",
        "x1 = [ 73.,  93.,  89.,  96.,  73.]\r\n",
        "x2 = [ 80.,  88.,  91.,  98.,  66.]\r\n",
        "x3 = [ 75.,  93.,  90., 100.,  70.]\r\n",
        "Y  = [152., 185., 180., 196., 142.]\r\n",
        "\r\n",
        "#weights\r\n",
        "w1 = tf.Variable(10.)\r\n",
        "w2 = tf.Variable(10.)\r\n",
        "w3 = tf.Variable(10.)\r\n",
        "b  = tf.Variable(10.)\r\n",
        "\r\n",
        "learning_rate = 0.000001\r\n",
        "\r\n",
        "for i in range(1000+1):\r\n",
        "    #tf.GradientTape() to record the gradient of the cost function\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "        hypothesis = w1 * x1 +  w2 * x2 + w3 * x3 + b\r\n",
        "        cost = tf.reduce_mean(tf.square(hypothesis - Y))\r\n",
        "    #calculates the gradients of the cost\r\n",
        "    w1_grad, w2_grad, w3_grad, b_grad = tape.gradient(cost, [w1, w2, w3, b])\r\n",
        "    \r\n",
        "    #update w1,w2,w3 and b\r\n",
        "    w1.assign_sub(learning_rate * w1_grad)\r\n",
        "    w2.assign_sub(learning_rate * w2_grad)\r\n",
        "    w3.assign_sub(learning_rate * w3_grad)\r\n",
        "    b.assign_sub(learning_rate * b_grad)\r\n",
        "\r\n",
        "    if i % 50 == 0:\r\n",
        "      print(\"{:5} | {:12.4f}\".format(i, cost.numpy()))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    0 | 5793889.5000\n",
            "   50 |   64291.1562\n",
            "  100 |     715.2903\n",
            "  150 |       9.8461\n",
            "  200 |       2.0152\n",
            "  250 |       1.9252\n",
            "  300 |       1.9210\n",
            "  350 |       1.9177\n",
            "  400 |       1.9145\n",
            "  450 |       1.9114\n",
            "  500 |       1.9081\n",
            "  550 |       1.9050\n",
            "  600 |       1.9018\n",
            "  650 |       1.8986\n",
            "  700 |       1.8955\n",
            "  750 |       1.8923\n",
            "  800 |       1.8892\n",
            "  850 |       1.8861\n",
            "  900 |       1.8829\n",
            "  950 |       1.8798\n",
            " 1000 |       1.8767\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj9zFsE515ed"
      },
      "source": [
        "**Multi-variable linear regression** (without Matrix)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCmB33aX2BHL",
        "outputId": "34a51564-673f-46e4-d288-f2ccace79d4b"
      },
      "source": [
        "#data and label\r\n",
        "x1 = [ 73.,  93.,  89.,  96.,  73.]\r\n",
        "x2 = [ 80.,  88.,  91.,  98.,  66.]\r\n",
        "x3 = [ 75.,  93.,  90., 100.,  70.]\r\n",
        "Y  = [152., 185., 180., 196., 142.]\r\n",
        "\r\n",
        "#random weights\r\n",
        "w1 = tf.Variable(tf.random.normal((1,)))\r\n",
        "w2 = tf.Variable(tf.random.normal((1,)))\r\n",
        "w3 = tf.Variable(tf.random.normal((1,)))\r\n",
        "b  = tf.Variable(tf.random.normal((1,)))\r\n",
        "\r\n",
        "learning_rate = 0.000001\r\n",
        "\r\n",
        "for i in range(1000+1):\r\n",
        "    #tf.GradientTape() to record the gradient of the cost function\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "        hypothesis = w1 * x1 +  w2 * x2 + w3 * x3 + b\r\n",
        "        cost = tf.reduce_mean(tf.square(hypothesis - Y))\r\n",
        "    #calculates the gradients of the cost\r\n",
        "    w1_grad, w2_grad, w3_grad, b_grad = tape.gradient(cost, [w1, w2, w3, b])\r\n",
        "    \r\n",
        "    #update w1,w2,w3 and b\r\n",
        "    w1.assign_sub(learning_rate * w1_grad)\r\n",
        "    w2.assign_sub(learning_rate * w2_grad)\r\n",
        "    w3.assign_sub(learning_rate * w3_grad)\r\n",
        "    b.assign_sub(learning_rate * b_grad)\r\n",
        "\r\n",
        "    if i % 50 == 0:\r\n",
        "      print(\"{:5} | {:12.4f}\".format(i, cost.numpy()))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    0 |   11325.9121\n",
            "   50 |     135.3618\n",
            "  100 |      11.1817\n",
            "  150 |       9.7940\n",
            "  200 |       9.7687\n",
            "  250 |       9.7587\n",
            "  300 |       9.7489\n",
            "  350 |       9.7389\n",
            "  400 |       9.7292\n",
            "  450 |       9.7194\n",
            "  500 |       9.7096\n",
            "  550 |       9.6999\n",
            "  600 |       9.6903\n",
            "  650 |       9.6806\n",
            "  700 |       9.6709\n",
            "  750 |       9.6612\n",
            "  800 |       9.6517\n",
            "  850 |       9.6421\n",
            "  900 |       9.6325\n",
            "  950 |       9.6229\n",
            " 1000 |       9.6134\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx_yQXiO2Geb"
      },
      "source": [
        "**Multi-variable linear regression** (with Matrix)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSyjMEIu2LTb",
        "outputId": "02090d42-92e1-447e-a183-2ee739c5897e"
      },
      "source": [
        "data = np.array([\r\n",
        "    # X1,   X2,    X3,   y\r\n",
        "    [ 73.,  80.,  75., 152. ],\r\n",
        "    [ 93.,  88.,  93., 185. ],\r\n",
        "    [ 89.,  91.,  90., 180. ],\r\n",
        "    [ 96.,  98., 100., 196. ],\r\n",
        "    [ 73.,  66.,  70., 142. ]\r\n",
        "], dtype=np.float32)\r\n",
        "\r\n",
        "# slice data\r\n",
        "X = data[:, :-1]\r\n",
        "y = data[:, [-1]]\r\n",
        "\r\n",
        "W = tf.Variable(tf.random.normal((3, 1)))\r\n",
        "b = tf.Variable(tf.random.normal((1,)))\r\n",
        "\r\n",
        "learning_rate = 0.000001\r\n",
        "\r\n",
        "# hypothesis, prediction function\r\n",
        "def predict(X):\r\n",
        "    return tf.matmul(X, W) + b\r\n",
        "\r\n",
        "print(\"epoch | cost\")\r\n",
        "\r\n",
        "n_epochs = 2000\r\n",
        "for i in range(n_epochs+1):\r\n",
        "    # tf.GradientTape() to record the gradient of the cost function\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "        cost = tf.reduce_mean((tf.square(predict(X) - y)))\r\n",
        "\r\n",
        "    # calculates the gradients of the loss\r\n",
        "    W_grad, b_grad = tape.gradient(cost, [W, b])\r\n",
        "\r\n",
        "    # updates parameters (W and b)\r\n",
        "    W.assign_sub(learning_rate * W_grad)\r\n",
        "    b.assign_sub(learning_rate * b_grad)\r\n",
        "    \r\n",
        "    if i % 100 == 0:\r\n",
        "        print(\"{:5} | {:10.4f}\".format(i, cost.numpy()))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch | cost\n",
            "    0 |  5455.5889\n",
            "  100 |    31.7444\n",
            "  200 |    30.9327\n",
            "  300 |    30.7893\n",
            "  400 |    30.6467\n",
            "  500 |    30.5053\n",
            "  600 |    30.3644\n",
            "  700 |    30.2241\n",
            "  800 |    30.0849\n",
            "  900 |    29.9462\n",
            " 1000 |    29.8081\n",
            " 1100 |    29.6711\n",
            " 1200 |    29.5347\n",
            " 1300 |    29.3990\n",
            " 1400 |    29.2640\n",
            " 1500 |    29.1298\n",
            " 1600 |    28.9960\n",
            " 1700 |    28.8632\n",
            " 1800 |    28.7312\n",
            " 1900 |    28.5995\n",
            " 2000 |    28.4689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsBW0cc-2OU2",
        "outputId": "6dba1537-8c7c-416f-8528-1270cc25c577"
      },
      "source": [
        "W.numpy()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.3685762],\n",
              "       [ 2.104772 ],\n",
              "       [-1.4229949]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG_Bt3P12QMZ",
        "outputId": "cba16321-ac50-4c6a-aa38-7fb6bdccd749"
      },
      "source": [
        "b.numpy()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.1783521], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiOQdAZP2UMR",
        "outputId": "018d6ea2-b194-40ca-cfd1-c173b7b91871"
      },
      "source": [
        "tf.matmul(X, W) + b"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 1), dtype=float32, numpy=\n",
              "array([[160.38489],\n",
              "       [178.98067],\n",
              "       [184.08965],\n",
              "       [194.17314],\n",
              "       [138.03304]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMIRsqcR2VGk"
      },
      "source": [
        "**predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_iMMjjR2WlK",
        "outputId": "1edd0492-1306-4063-889d-19f7f06258af"
      },
      "source": [
        "Y #labels: real value"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[152.0, 185.0, 180.0, 196.0, 142.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLFqERzz2dto",
        "outputId": "76af23f8-a9ec-4c00-a643-0a6378ba2050"
      },
      "source": [
        "predict(X).numpy() #prediction"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[160.38489],\n",
              "       [178.98067],\n",
              "       [184.08965],\n",
              "       [194.17314],\n",
              "       [138.03304]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cj_UAkLi2g76",
        "outputId": "1c748530-e7c2-41fc-dfe4-170cb0901ee0"
      },
      "source": [
        "predict([[ 89.,  95.,  92.],[ 84.,  92.,  85.]]).numpy()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[189.66275],\n",
              "       [186.46652]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}